{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Assignment 4. Long Short Term Memory (LSTM) Network for Named Entity Recognition (NER)\n",
    "\n",
    "**Total points**: 50 + (10 bonus)\n",
    "\n",
    "In this assignment, you will implement a Long Short Term Memory (LSTM) network for Named Entity Recognition (NER). \n",
    "\n",
    "Re-use the code in Lab 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_tag_indices_from_scores\n",
    "from metrics import MetricsHandler\n",
    "\n",
    "labels_str = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "labels_int = list(range(len(labels_str)))\n",
    "train_metrics = MetricsHandler(labels_int)\n",
    "\n",
    "def train_model(model, data_loader, optimizer, loss_func, train_metrics, num_epochs=5, **kwargs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs, targets = batch\n",
    "            output = model(inputs) # This is just a demo\n",
    "            loss = loss_func(output, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predictions = get_tag_indices_from_scores(output.detach().cpu().numpy())\n",
    "            train_metrics.update(predictions, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(data_loader)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "    return model, train_metrics, losses\n",
    "\n",
    "def evaluate_model(model, data_loader, loss_func, eval_metrics, **kwargs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Other Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
