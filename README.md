# SUSTech CS310 Natural Language Processing

This course introduces Natural Language Processing (NLP) and Computational Linguistics (CL). NLP focuses on practical applications of human language processing, while CL emphasizes theoretical research in computational methods for language analysis. The curriculum combines both aspects (70% NLP, 30% CL), covering topics from word semantics to machine translation, with hands-on implementation practices.


## Repository Structure

```
CS310-Natural_Language_Processing/
├── assignments/           # Assignment submissions and related files
├── lab/                  # Lab exercises and practice
│   ├── lab1/            # Introduction to NLP basics
│   ├── lab2/            # Text processing fundamentals
│   ├── lab3/            # Language modeling
│   ├── lab4/            # Neural networks basics
│   ├── lab5/            # Word embeddings
│   ├── lab6/            # RNN and LSTM
│   ├── lab7/            # Attention mechanism
│   ├── lab8/            # Advanced NLP models
│   └── lab9/            # Transformer implementation
├── slides/              # Course lecture slides
└── README.md           # Course overview and repository information
```

## Lab Contents

Each lab focuses on specific NLP concepts and implementations:

- Lab 1: Introduction to NLP tools and basic text processing
- Lab 2: Text preprocessing and feature extraction
- Lab 3: N-gram language models and smoothing techniques
- Lab 4: Neural network fundamentals for NLP
- Lab 5: Word2Vec and other embedding techniques
- Lab 6: Sequence modeling with RNN/LSTM
- Lab 7: Attention mechanisms in NLP
- Lab 8: Advanced model architectures
- Lab 9: Transformer architecture implementation


## Assignments Overview

### Assignment 1: Text Classification (50/50)
- Implementation of text classification models
- Data preprocessing and feature extraction
- Evaluation of different classification algorithms
- Focus on sentiment analysis techniques

### Assignment 2: Language Models (48/50)
- Development of n-gram language models
- Implementation of smoothing techniques
- Perplexity calculation and model evaluation
- Text generation using statistical methods

### Assignment 3: Neural Networks for NLP (50/50)
- Implementation of neural network architectures
- Word embeddings and representation learning
- Deep learning models for text processing
- Training and optimization techniques

### Assignment 4: Transformer Architecture
- Implementation of multi-head attention mechanism
- Development of positional encoding
- Building transformer encoder and decoder
- Application in sequence-to-sequence tasks

## Assignment Scores Summary
| Assignment | Score | Total |
|------------|--------|--------|
| A1 | 50 | 50 |
| A2 | 48 | 50 |
| A3 | 50 | 50 |

Total Score: 148/150 (98.67%)
